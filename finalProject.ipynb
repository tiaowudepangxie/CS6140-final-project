{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "Grop Member:\n",
        "Lei Li, Yichen Han, and Zihan Chen"
      ],
      "metadata": {
        "id": "hibNNoJq-06j"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Data pre-procession"
      ],
      "metadata": {
        "id": "B76i9fjThcBP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import json\n",
        "\n",
        "\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "\n",
        "\n",
        "name_dict = {\n",
        "    \"apple\": 0, \"banana\": 1, \"guava\": 2, \"lime\": 3, \"orange\": 4, \"pomegranate\": 5\n",
        "}\n",
        "\n",
        "# summary the the pictures in each category\n",
        "name2data = {}\n",
        "\n",
        "data_root_path = '/content/drive/My Drive/FruitDataSet/'\n",
        "test_file_path = data_root_path + \"test.list\"\n",
        "train_file_path = data_root_path + \"train.list\"\n",
        "readme_file = data_root_path + \"readme.json\"\n",
        "\n",
        "\n",
        "def save_train_test_file(path, name):\n",
        "  if name not in name2data:\n",
        "    name2data[name] = []\n",
        "\n",
        "  name2data[name].append(path)\n",
        "\n",
        "\n",
        "for d in os.listdir(data_root_path):\n",
        "  # print(d)\n",
        "  full_path = data_root_path + d\n",
        "  if os.path.isdir(full_path):\n",
        "    imgs = os.listdir(full_path)\n",
        "    for img in imgs:\n",
        "      save_train_test_file(full_path + \"/\" + img, d.lower())\n",
        "  else:\n",
        "    pass\n",
        "\n",
        "\n",
        "# clear the file first\n",
        "with open(test_file_path, 'w') as f:\n",
        "  pass\n",
        "\n",
        "with open(train_file_path, 'w') as f:\n",
        "  pass\n",
        "\n",
        "# now let's divide the data into train set and test set. 1 : 10\n",
        "for name, imgs in name2data.items():\n",
        "  print(name, \"  \", len(imgs))\n",
        "  n = len(imgs)\n",
        "  n = 100\n",
        "  for i in range(n):\n",
        "    if i % 10:\n",
        "      with open(train_file_path, 'a') as f:\n",
        "        line = f\"{imgs[i]}\\t{name_dict[name]}\\n\"\n",
        "        f.write(line)\n",
        "    else:\n",
        "      with open(test_file_path, 'a') as f:\n",
        "        line = f\"{imgs[i]}\\t{name_dict[name]}\\n\"\n",
        "        f.write(line)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JP1uWKoXhjHP",
        "outputId": "834228fa-eae8-4375-b5af-383ecb5e649f"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n",
            "apple    1149\n",
            "orange    1216\n",
            "banana    1113\n",
            "lime    1094\n",
            "pomegranate    5940\n",
            "guava    1152\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Model build and training"
      ],
      "metadata": {
        "id": "Yin2m2SltUrY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install paddlepaddle-gpu\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "acfJhPXfUxgU",
        "outputId": "66d5b52d-50de-494c-e9c7-eb78c7a5dfa0"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting paddlepaddle-gpu\n",
            "  Downloading paddlepaddle_gpu-2.6.1-cp310-cp310-manylinux1_x86_64.whl (758.9 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m758.9/758.9 MB\u001b[0m \u001b[31m2.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting httpx (from paddlepaddle-gpu)\n",
            "  Downloading httpx-0.27.0-py3-none-any.whl (75 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m75.6/75.6 kB\u001b[0m \u001b[31m11.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: numpy>=1.13 in /usr/local/lib/python3.10/dist-packages (from paddlepaddle-gpu) (1.25.2)\n",
            "Requirement already satisfied: Pillow in /usr/local/lib/python3.10/dist-packages (from paddlepaddle-gpu) (9.4.0)\n",
            "Requirement already satisfied: decorator in /usr/local/lib/python3.10/dist-packages (from paddlepaddle-gpu) (4.4.2)\n",
            "Collecting astor (from paddlepaddle-gpu)\n",
            "  Downloading astor-0.8.1-py2.py3-none-any.whl (27 kB)\n",
            "Requirement already satisfied: opt-einsum==3.3.0 in /usr/local/lib/python3.10/dist-packages (from paddlepaddle-gpu) (3.3.0)\n",
            "Requirement already satisfied: protobuf>=3.20.2 in /usr/local/lib/python3.10/dist-packages (from paddlepaddle-gpu) (3.20.3)\n",
            "Requirement already satisfied: anyio in /usr/local/lib/python3.10/dist-packages (from httpx->paddlepaddle-gpu) (3.7.1)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.10/dist-packages (from httpx->paddlepaddle-gpu) (2024.2.2)\n",
            "Collecting httpcore==1.* (from httpx->paddlepaddle-gpu)\n",
            "  Downloading httpcore-1.0.5-py3-none-any.whl (77 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m77.9/77.9 kB\u001b[0m \u001b[31m11.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: idna in /usr/local/lib/python3.10/dist-packages (from httpx->paddlepaddle-gpu) (3.7)\n",
            "Requirement already satisfied: sniffio in /usr/local/lib/python3.10/dist-packages (from httpx->paddlepaddle-gpu) (1.3.1)\n",
            "Collecting h11<0.15,>=0.13 (from httpcore==1.*->httpx->paddlepaddle-gpu)\n",
            "  Downloading h11-0.14.0-py3-none-any.whl (58 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m58.3/58.3 kB\u001b[0m \u001b[31m8.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: exceptiongroup in /usr/local/lib/python3.10/dist-packages (from anyio->httpx->paddlepaddle-gpu) (1.2.1)\n",
            "Installing collected packages: h11, astor, httpcore, httpx, paddlepaddle-gpu\n",
            "Successfully installed astor-0.8.1 h11-0.14.0 httpcore-1.0.5 httpx-0.27.0 paddlepaddle-gpu-2.6.1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "pip install Pillow"
      ],
      "metadata": {
        "id": "F13AbaL_bIVM",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7e02294e-6d48-4d5e-815d-0915b6c61072"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: Pillow in /usr/local/lib/python3.10/dist-packages (9.4.0)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import numpy as np\n",
        "from PIL import Image\n",
        "import paddle\n",
        "import paddle.nn as nn\n",
        "import paddle.nn.functional as F\n",
        "from paddle.io import Dataset, DataLoader\n",
        "import paddle.vision.transforms as T\n",
        "\n",
        "data_root_path = '/content/drive/My Drive/FruitDataSet/'\n",
        "test_file_path = data_root_path + \"test.list\"\n",
        "train_file_path = data_root_path + \"train.list\"\n",
        "\n",
        "# Transformation for image\n",
        "transform = T.Compose([\n",
        "    T.Resize((100, 100)), # Resizes the image to 100 x 100\n",
        "    T.ToTensor(), # Converts to Tensor, scales to [0, 1] by dividing by 255\n",
        "])\n",
        "\n",
        "# Custom Dataset class\n",
        "class CustomDataset(Dataset):\n",
        "    def __init__(self, data_file):\n",
        "        super(CustomDataset, self).__init__()\n",
        "        self.data = []\n",
        "        with open(data_file, 'r') as f:\n",
        "            for line in f:\n",
        "                img_path, label = line.strip().split('\\t')\n",
        "                self.data.append((img_path, int(label)))\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        img_path, label = self.data[idx]\n",
        "        img = Image.open(img_path).convert('RGB') # Ensure image is RGB\n",
        "        img = transform(img) # Apply transformations\n",
        "        return img, label\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.data)\n",
        "\n",
        "# Define the model\n",
        "\n",
        "\n",
        "class ConvolutionalNeuralNetwork(nn.Layer):\n",
        "    def __init__(self, type_size):\n",
        "        super(ConvolutionalNeuralNetwork, self).__init__()\n",
        "\n",
        "        # Define the first convolutional pooling layer\n",
        "        self.conv_pool_1 = nn.Sequential(\n",
        "            nn.Conv2D(in_channels=3, out_channels=32, kernel_size=3, padding=1),\n",
        "            nn.ReLU(),\n",
        "            nn.MaxPool2D(kernel_size=2, stride=2),\n",
        "            nn.Dropout(p=0.5)\n",
        "        )\n",
        "\n",
        "        # Define the second convolutional pooling layer\n",
        "        self.conv_pool_2 = nn.Sequential(\n",
        "            nn.Conv2D(in_channels=32, out_channels=64, kernel_size=3, padding=1),\n",
        "            nn.ReLU(),\n",
        "            nn.MaxPool2D(kernel_size=2, stride=2),\n",
        "            nn.Dropout(p=0.5)\n",
        "        )\n",
        "\n",
        "        # Define the third convolutional pooling layer\n",
        "        self.conv_pool_3 = nn.Sequential(\n",
        "            nn.Conv2D(in_channels=64, out_channels=64, kernel_size=3, padding=1),\n",
        "            nn.ReLU(),\n",
        "            nn.MaxPool2D(kernel_size=2, stride=2),\n",
        "            nn.Dropout(p=0.5)\n",
        "        )\n",
        "\n",
        "        # Define the first fully connected layer\n",
        "        self.fc1 = nn.Sequential(\n",
        "            nn.Linear(in_features=9216, out_features=512),  # !!!`in_features`\n",
        "            nn.ReLU(),\n",
        "            nn.Dropout(p=0.5)\n",
        "        )\n",
        "\n",
        "        # Define the prediction fully connected layer\n",
        "        self.fc2 = nn.Linear(in_features=512, out_features=type_size)\n",
        "\n",
        "    def forward(self, image):\n",
        "        x = self.conv_pool_1(image)\n",
        "        x = self.conv_pool_2(x)\n",
        "        x = self.conv_pool_3(x)\n",
        "\n",
        "        # Flatten the output for the fully connected layer\n",
        "        x = paddle.flatten(x, start_axis=1)\n",
        "\n",
        "        # Apply the first fully connected layer and dropout\n",
        "        x = self.fc1(x)\n",
        "\n",
        "        # Apply the second fully connected layer for prediction\n",
        "        x = self.fc2(x)\n",
        "\n",
        "        # Apply softmax for prediction\n",
        "        # x = nn.functional.softmax(x, axis=1)\n",
        "\n",
        "        return x\n",
        "\n",
        "# Initialize the model and optimizer\n",
        "model = ConvolutionalNeuralNetwork(6)\n",
        "optimizer = paddle.optimizer.Adam(learning_rate=0.001, parameters=model.parameters())\n",
        "\n",
        "# Use GPU for training\n",
        "paddle.set_device('gpu:0')\n",
        "\n",
        "# Create the dataset and data loader\n",
        "train_dataset = CustomDataset(train_file_path) # Make sure to provide the correct path\n",
        "train_loader = DataLoader(dataset=train_dataset, batch_size=32, shuffle=True)\n",
        "\n",
        "# Training loop\n",
        "for epoch in range(10):\n",
        "    for batch_id, (images, labels) in enumerate(train_loader):\n",
        "        # Forward pass\n",
        "        predicts = model(images)\n",
        "\n",
        "        # Convert labels to tensor\n",
        "        labels = paddle.to_tensor(labels, dtype='int64')\n",
        "\n",
        "        # Calculate the loss\n",
        "        loss = F.cross_entropy(predicts, labels)\n",
        "\n",
        "        # Backward and optimize\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        optimizer.clear_grad()\n",
        "\n",
        "        if batch_id % 20 == 0:\n",
        "            print(f\"Epoch {epoch}, Batch {batch_id}, Loss {loss.numpy()}\")\n",
        "\n",
        "print('Training complete')\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oyL9ySi2ahBZ",
        "outputId": "299a9ce3-914b-4058-a2b1-a41e78bcbc47"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 0, Batch 0, Loss 7.4582366943359375\n",
            "Epoch 1, Batch 0, Loss 1.8055946826934814\n",
            "Epoch 2, Batch 0, Loss 1.7835028171539307\n",
            "Epoch 3, Batch 0, Loss 1.768263816833496\n",
            "Epoch 4, Batch 0, Loss 1.466644525527954\n",
            "Epoch 5, Batch 0, Loss 0.70966637134552\n",
            "Epoch 6, Batch 0, Loss 0.5495848655700684\n",
            "Epoch 7, Batch 0, Loss 0.8474939465522766\n",
            "Epoch 8, Batch 0, Loss 0.7155379056930542\n",
            "Epoch 9, Batch 0, Loss 0.21582749485969543\n",
            "Training complete\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def validate(model, data_loader):\n",
        "    model.eval()  # Set the model to evaluation mode\n",
        "    total_correct = 0\n",
        "    total_samples = 0\n",
        "    loss_list = []\n",
        "\n",
        "    for batch_id, (images, labels) in enumerate(data_loader):\n",
        "        predicts = model(images)\n",
        "        labels = paddle.to_tensor(labels, dtype='int64').unsqueeze(-1)  # Add a dimension to labels\n",
        "        loss = F.cross_entropy(predicts, labels)\n",
        "        loss_list.append(loss.numpy())\n",
        "\n",
        "        # Calculate accuracy using Paddle's built-in function\n",
        "        predicted_labels = paddle.argmax(predicts, axis=1).unsqueeze(-1)\n",
        "        correct = paddle.equal(predicted_labels, labels).astype(paddle.int32)\n",
        "        total_correct += paddle.sum(correct).numpy()\n",
        "        total_samples += labels.shape[0]\n",
        "\n",
        "        # Print image details\n",
        "        predicted_labels = predicted_labels.numpy().flatten()\n",
        "        actual_labels = labels.squeeze(-1).numpy()\n",
        "        probabilities = predicts.numpy()\n",
        "        for img_idx in range(len(images)):\n",
        "            print(f\"Image: {data_loader.dataset.data[batch_id * BATCH_SIZE + img_idx][0]}, \"\n",
        "                  f\"Actual: {actual_labels[img_idx]}, \"\n",
        "                  f\"Predicted: {predicted_labels[img_idx]}, \"\n",
        "                  f\"Probabilities: {probabilities[img_idx]}\")\n",
        "\n",
        "    avg_loss = np.mean(loss_list)\n",
        "    accuracy = total_correct / total_samples\n",
        "    print(f\"Total Correct: {total_correct}, Total Samples: {total_samples}, Calculated Accuracy: {accuracy}\")\n",
        "    return avg_loss, accuracy\n",
        "\n",
        "\n",
        "BATCH_SIZE = 32\n",
        "test_dataset = CustomDataset(test_file_path)\n",
        "test_loader = DataLoader(dataset=test_dataset, batch_size=BATCH_SIZE, shuffle=False)\n",
        "\n",
        "\n",
        "# After the training loop\n",
        "avg_loss, accuracy = validate(model, test_loader)\n",
        "print(f\"Validation Loss: {avg_loss}, Accuracy: {accuracy}\")\n"
      ],
      "metadata": {
        "id": "zcZNzF8Ie9Mx",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "335dfb9a-d5ad-4100-9b65-d5dec726945e"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Image: /content/drive/My Drive/FruitDataSet/Apple/20190809_122017.jpg, Actual: 0, Predicted: 0, Probabilities: [ 3.2886198  -0.1497783   0.77602285  0.18880889  0.8292114  -0.88134474]\n",
            "Image: /content/drive/My Drive/FruitDataSet/Apple/20190809_122140.jpg, Actual: 0, Predicted: 0, Probabilities: [ 7.8425803  1.2932645  6.874145  -5.5826545 -5.245053   1.621631 ]\n",
            "Image: /content/drive/My Drive/FruitDataSet/Apple/20190809_122237.jpg, Actual: 0, Predicted: 0, Probabilities: [ 5.7204633   0.7394698   5.4821277  -4.7466736  -0.20485233  0.4223248 ]\n",
            "Image: /content/drive/My Drive/FruitDataSet/Apple/20190809_122435.jpg, Actual: 0, Predicted: 0, Probabilities: [ 6.0690064   0.36053398  5.035973   -1.913502    1.714533   -2.8261306 ]\n",
            "Image: /content/drive/My Drive/FruitDataSet/Apple/20190809_122710.jpg, Actual: 0, Predicted: 0, Probabilities: [ 5.3617005  -0.23567587  3.627666   -1.070859   -0.8148127  -1.7736454 ]\n",
            "Image: /content/drive/My Drive/FruitDataSet/Apple/20190809_122752.jpg, Actual: 0, Predicted: 2, Probabilities: [ 4.148809   0.6776351  4.6425557 -2.0384169 -0.3037642 -1.607733 ]\n",
            "Image: /content/drive/My Drive/FruitDataSet/Apple/20190809_150645.jpg, Actual: 0, Predicted: 0, Probabilities: [ 4.6072726 -2.886441   3.181105  -4.0800767  3.7549202  2.196362 ]\n",
            "Image: /content/drive/My Drive/FruitDataSet/Apple/20190809_150921.jpg, Actual: 0, Predicted: 2, Probabilities: [ 0.9857602  -0.11173332  1.096349    0.15943374  0.26656863 -0.7880911 ]\n",
            "Image: /content/drive/My Drive/FruitDataSet/Apple/20190809_151056.jpg, Actual: 0, Predicted: 0, Probabilities: [ 6.11947    -2.5824978   1.9823977  -4.3014293   0.91801536  3.9878657 ]\n",
            "Image: /content/drive/My Drive/FruitDataSet/Apple/20190809_153420.jpg, Actual: 0, Predicted: 0, Probabilities: [13.086864  -3.2417262  6.01675   -7.9578137  2.0571842  2.7700534]\n",
            "Image: /content/drive/My Drive/FruitDataSet/Orange/IMG_1876.JPG, Actual: 4, Predicted: 4, Probabilities: [ 0.724736  -1.4696223 -0.363432  -1.1342821  2.906741   1.8343195]\n",
            "Image: /content/drive/My Drive/FruitDataSet/Orange/IMG_1895.JPG, Actual: 4, Predicted: 4, Probabilities: [ 0.8528262  -2.2436602  -0.21530606 -1.9744301   4.4729743   2.8562384 ]\n",
            "Image: /content/drive/My Drive/FruitDataSet/Orange/IMG_1906.JPG, Actual: 4, Predicted: 4, Probabilities: [ 0.9685995  -2.3095777  -0.08260868 -1.8960034   4.8502007   2.5514963 ]\n",
            "Image: /content/drive/My Drive/FruitDataSet/Orange/IMG_1912.JPG, Actual: 4, Predicted: 4, Probabilities: [ 0.7201691  -2.522397    0.42123175 -2.7167015   5.639701    2.9533746 ]\n",
            "Image: /content/drive/My Drive/FruitDataSet/Orange/IMG_1919.JPG, Actual: 4, Predicted: 4, Probabilities: [ 0.15956917 -1.6435982  -0.11402394 -1.9740374   3.8508968   2.7957351 ]\n",
            "Image: /content/drive/My Drive/FruitDataSet/Orange/IMG_1937.JPG, Actual: 4, Predicted: 4, Probabilities: [ 2.578754  -3.4012132  1.3520306 -2.4888945  5.1394134  2.406371 ]\n",
            "Image: /content/drive/My Drive/FruitDataSet/Orange/IMG_1943.JPG, Actual: 4, Predicted: 4, Probabilities: [ 1.9516116  -3.3723192   0.06862758 -1.8875773   5.7026343   3.00327   ]\n",
            "Image: /content/drive/My Drive/FruitDataSet/Orange/IMG_1950.JPG, Actual: 4, Predicted: 4, Probabilities: [ 2.5882425 -1.6106043  2.5459921 -1.4683187  5.352625  -1.3957268]\n",
            "Image: /content/drive/My Drive/FruitDataSet/Orange/IMG_1989.JPG, Actual: 4, Predicted: 5, Probabilities: [ 0.3144569  -2.3981848   0.44472963 -5.657641    6.227892    6.7157316 ]\n",
            "Image: /content/drive/My Drive/FruitDataSet/Orange/IMG_1999.JPG, Actual: 4, Predicted: 4, Probabilities: [ 2.9562204  -1.92551     1.834124   -2.1110249   6.940334   -0.45226425]\n",
            "Image: /content/drive/My Drive/FruitDataSet/Banana/IMG20200730132319.jpg, Actual: 1, Predicted: 2, Probabilities: [  9.957897    1.2024589  10.793762  -11.459444   -5.515608    6.3087525]\n",
            "Image: /content/drive/My Drive/FruitDataSet/Banana/IMG_0121.JPG, Actual: 1, Predicted: 1, Probabilities: [ 0.2964364   0.6676083   0.64609766 -0.52462757 -0.39269546 -0.02791961]\n",
            "Image: /content/drive/My Drive/FruitDataSet/Banana/IMG_8482.JPG, Actual: 1, Predicted: 1, Probabilities: [ 0.9923881   2.0630414   1.8136579  -0.5612595  -0.39814958 -1.323577  ]\n",
            "Image: /content/drive/My Drive/FruitDataSet/Banana/IMG_8492.JPG, Actual: 1, Predicted: 1, Probabilities: [ 0.45389915  1.7378778   0.4720102  -0.435842   -0.7952334  -0.3428604 ]\n",
            "Image: /content/drive/My Drive/FruitDataSet/Banana/IMG_8502.JPG, Actual: 1, Predicted: 1, Probabilities: [ 1.0566738  2.4978697  1.5177915 -0.5270099 -1.233305  -1.0977494]\n",
            "Image: /content/drive/My Drive/FruitDataSet/Banana/IMG_8515.JPG, Actual: 1, Predicted: 1, Probabilities: [ 0.58464205  1.9118953   1.1915691  -0.5219349  -1.0022043  -0.57995963]\n",
            "Image: /content/drive/My Drive/FruitDataSet/Banana/IMG_8514.JPG, Actual: 1, Predicted: 1, Probabilities: [ 0.526973    1.9013448   1.1331632  -0.4685926  -1.0699254  -0.55820304]\n",
            "Image: /content/drive/My Drive/FruitDataSet/Banana/IMG_8524.JPG, Actual: 1, Predicted: 1, Probabilities: [ 0.57757866  1.7369108   0.83418465  0.02838546 -0.68443966 -0.97743046]\n",
            "Image: /content/drive/My Drive/FruitDataSet/Banana/IMG_8540.JPG, Actual: 1, Predicted: 1, Probabilities: [ 1.2223206   2.4585454   1.4474442   0.01860816 -1.1607898  -1.4876356 ]\n",
            "Image: /content/drive/My Drive/FruitDataSet/Banana/IMG_8550.JPG, Actual: 1, Predicted: 1, Probabilities: [ 0.6525529   2.300246    1.3381097   0.5448566  -0.65088016 -1.9262571 ]\n",
            "Image: /content/drive/My Drive/FruitDataSet/Lime/IMG20200729172425.jpg, Actual: 3, Predicted: 2, Probabilities: [ 0.2320246   0.45043406  0.58681214  0.5380623  -0.18658587 -0.798438  ]\n",
            "Image: /content/drive/My Drive/FruitDataSet/Lime/IMG_20190902_102406.jpg, Actual: 3, Predicted: 3, Probabilities: [ 0.5484581   0.7212858   1.6030887   2.9563677  -0.41987678 -3.4577024 ]\n",
            "Image: /content/drive/My Drive/FruitDataSet/Lime/IMG_20190902_102419_1.jpg, Actual: 3, Predicted: 3, Probabilities: [ 1.4180275  -0.4659224   3.1205692   4.9494696   0.21254073 -5.8542504 ]\n",
            "Image: /content/drive/My Drive/FruitDataSet/Lime/IMG_20190902_102425.jpg, Actual: 3, Predicted: 3, Probabilities: [ 1.2513249  -0.29378417  2.8409731   4.84942     0.03002072 -5.5512166 ]\n",
            "Image: /content/drive/My Drive/FruitDataSet/Lime/IMG_20190902_102440.jpg, Actual: 3, Predicted: 3, Probabilities: [ 1.0110216   0.07365448  2.633348    3.803978    0.13153902 -4.667957  ]\n",
            "Image: /content/drive/My Drive/FruitDataSet/Lime/IMG_20190902_102445.jpg, Actual: 3, Predicted: 3, Probabilities: [ 1.0310386   0.09523544  2.5966678   3.8557434   0.08526351 -4.683299  ]\n",
            "Image: /content/drive/My Drive/FruitDataSet/Lime/IMG_20190902_102510.jpg, Actual: 3, Predicted: 2, Probabilities: [ 1.3950216  -0.11174449  3.8935359   3.794957    0.67638034 -5.6140256 ]\n",
            "Image: /content/drive/My Drive/FruitDataSet/Lime/IMG_20190902_102500.jpg, Actual: 3, Predicted: 3, Probabilities: [ 0.7825806  -0.02981535  2.5183685   3.8150604  -0.02304135 -4.5521374 ]\n",
            "Image: /content/drive/My Drive/FruitDataSet/Lime/IMG_20190902_102523_1.jpg, Actual: 3, Predicted: 3, Probabilities: [ 1.453413    0.17200941  3.3033218   5.033371   -0.12252332 -6.190822  ]\n",
            "Image: /content/drive/My Drive/FruitDataSet/Lime/IMG_20190902_102524.jpg, Actual: 3, Predicted: 3, Probabilities: [ 1.4590665   0.19532126  3.2544558   5.0264463  -0.14969964 -6.1559577 ]\n",
            "Image: /content/drive/My Drive/FruitDataSet/Pomegranate/20190820_144711.jpg, Actual: 5, Predicted: 5, Probabilities: [ 0.83911145 -1.7460803  -0.53778696 -3.3572228   1.6734961   6.6110516 ]\n",
            "Image: /content/drive/My Drive/FruitDataSet/Pomegranate/20190820_144718.jpg, Actual: 5, Predicted: 5, Probabilities: [ 0.9082538  -1.6705034  -0.20636158 -3.1665876   1.4827281   5.614658  ]\n",
            "Image: /content/drive/My Drive/FruitDataSet/Pomegranate/20190820_145700.jpg, Actual: 5, Predicted: 5, Probabilities: [ 2.1588602 -2.2451475 -0.3342799 -5.982023   2.6351295  9.893273 ]\n",
            "Image: /content/drive/My Drive/FruitDataSet/Pomegranate/20190820_150053.jpg, Actual: 5, Predicted: 5, Probabilities: [  5.5668063  -0.6287257   6.1582265 -13.805644   -3.6852634  14.630989 ]\n",
            "Image: /content/drive/My Drive/FruitDataSet/Pomegranate/20190820_145826.jpg, Actual: 5, Predicted: 5, Probabilities: [ 1.5192816 -2.086289  -0.5494925 -6.3607755  1.0671827 11.020118 ]\n",
            "Image: /content/drive/My Drive/FruitDataSet/Pomegranate/20190820_145844.jpg, Actual: 5, Predicted: 5, Probabilities: [ 1.6924618 -2.912215  -1.0753002 -4.537064   2.6706715  9.489017 ]\n",
            "Image: /content/drive/My Drive/FruitDataSet/Pomegranate/20190820_150135.jpg, Actual: 5, Predicted: 5, Probabilities: [ 3.127224  -2.0495126  1.584709  -8.343931   0.8986051 11.124998 ]\n",
            "Image: /content/drive/My Drive/FruitDataSet/Pomegranate/20190820_145749.jpg, Actual: 5, Predicted: 5, Probabilities: [ 2.4775338 -2.5697763 -0.5342785 -6.485436   2.3722174 11.163648 ]\n",
            "Image: /content/drive/My Drive/FruitDataSet/Pomegranate/20190820_150052.jpg, Actual: 5, Predicted: 5, Probabilities: [ 1.9167273  -2.502518   -0.22135155 -6.556884    3.0453448   9.908192  ]\n",
            "Image: /content/drive/My Drive/FruitDataSet/Pomegranate/20190820_150101.jpg, Actual: 5, Predicted: 5, Probabilities: [ 5.2142663  -0.67119306  2.7782304  -9.95775    -2.313923   11.479726  ]\n",
            "Image: /content/drive/My Drive/FruitDataSet/Guava/20190813_130451.jpg, Actual: 2, Predicted: 2, Probabilities: [ 4.203541   2.1133726  6.7419553 -5.6268954 -3.7179382  2.048717 ]\n",
            "Image: /content/drive/My Drive/FruitDataSet/Guava/20190813_130447.jpg, Actual: 2, Predicted: 2, Probabilities: [ 3.3090725   1.9024544   5.4724116  -3.7066607  -1.9388757   0.16723153]\n",
            "Image: /content/drive/My Drive/FruitDataSet/Guava/20190813_130453.jpg, Actual: 2, Predicted: 2, Probabilities: [ 1.87397    1.1543801  4.2457433 -3.8958416 -1.4558669  2.1108265]\n",
            "Image: /content/drive/My Drive/FruitDataSet/Guava/20190813_131137.jpg, Actual: 2, Predicted: 2, Probabilities: [ 0.94287235  1.423842    4.270367   -0.52441174  0.39258835 -1.8885591 ]\n",
            "Image: /content/drive/My Drive/FruitDataSet/Guava/20190813_131251.jpg, Actual: 2, Predicted: 2, Probabilities: [ 3.039176   1.4018596  4.0525737 -1.0229876 -1.7921625 -1.4456798]\n",
            "Image: /content/drive/My Drive/FruitDataSet/Guava/20190813_131151.jpg, Actual: 2, Predicted: 2, Probabilities: [ 2.5429323   1.5969746   3.4601386  -0.3990912  -0.36777893 -2.6682408 ]\n",
            "Image: /content/drive/My Drive/FruitDataSet/Guava/20190813_131323.jpg, Actual: 2, Predicted: 2, Probabilities: [ 2.9313219  2.379388   5.7422643 -0.5765888 -0.9287407 -3.306029 ]\n",
            "Image: /content/drive/My Drive/FruitDataSet/Guava/IMG20200728184234.jpg, Actual: 2, Predicted: 2, Probabilities: [ 0.9608957   0.03336936  1.1711088  -0.36065203  0.6373809  -0.69830674]\n",
            "Image: /content/drive/My Drive/FruitDataSet/Guava/IMG20200728184256.jpg, Actual: 2, Predicted: 2, Probabilities: [ 1.2247711 -0.7152415  2.1236966 -0.7458864  1.1650295 -0.8770713]\n",
            "Image: /content/drive/My Drive/FruitDataSet/Guava/IMG20200728184310.jpg, Actual: 2, Predicted: 2, Probabilities: [ 1.1955353  -0.3224185   1.6187874  -1.3614827   0.9949069  -0.02750438]\n",
            "Total Correct: 54, Total Samples: 60, Calculated Accuracy: 0.9\n",
            "Validation Loss: 0.5215149521827698, Accuracy: 0.9\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "12S2NnP7k_eN"
      }
    }
  ]
}